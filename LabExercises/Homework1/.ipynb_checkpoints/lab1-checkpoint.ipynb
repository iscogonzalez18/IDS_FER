{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory excercise 1 and 2\n",
    "The notebook contains excercise connected to the auditory excerices 1 and 2. For any questions feel free to contact assistans: eda.jovicic@fer.hr and filip.tomas@fer.hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the dataset *student_score.csv*. When loading the dataset watch out for the index column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"students_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print the size of the dataset. List the number of examples and the number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples = 30641\n",
      "Number of features = 16\n"
     ]
    }
   ],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "\n",
    "num_examples, num_features = data.shape\n",
    "print(f'Number of examples = {num_examples}\\nNumber of features = {num_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Show the first 5 examples of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  StudentId  Gender EthnicGroup          ParentEduc  \\\n",
      "0           0     520645  female         NaN   bachelor's degree   \n",
      "1           1     303683  female     group C        some college   \n",
      "2           2     457351  female     group B     master's degree   \n",
      "3           3     812988    male     group A  associate's degree   \n",
      "4           4     594678    male     group C        some college   \n",
      "\n",
      "      LunchType TestPrep ParentMaritalStatus PracticeSport IsFirstChild  \\\n",
      "0      standard     none             married     regularly          yes   \n",
      "1      standard      NaN             married     sometimes          yes   \n",
      "2      standard     none              single     sometimes          yes   \n",
      "3  free/reduced     none             married         never           no   \n",
      "4      standard     none             married     sometimes          yes   \n",
      "\n",
      "   NrSiblings TransportMeans WklyStudyHours  MathScore  ReadingScore  \\\n",
      "0         3.0     school_bus            < 5         71            71   \n",
      "1         0.0            NaN         5 - 10         69            90   \n",
      "2         4.0     school_bus            < 5         87            93   \n",
      "3         1.0            NaN         5 - 10         45            56   \n",
      "4         0.0     school_bus         5 - 10         76            78   \n",
      "\n",
      "   WritingScore  \n",
      "0            74  \n",
      "1            88  \n",
      "2            91  \n",
      "3            42  \n",
      "4            75  \n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the third example from the dataset print for every feature the type of data (int, float, string or bool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Unnamed: 0 -> 2 is <class 'numpy.int64'>\n",
      "Feature StudentId -> 457351 is <class 'numpy.int64'>\n",
      "Feature Gender -> female is <class 'str'>\n",
      "Feature EthnicGroup -> group B is <class 'str'>\n",
      "Feature ParentEduc -> master's degree is <class 'str'>\n",
      "Feature LunchType -> standard is <class 'str'>\n",
      "Feature TestPrep -> none is <class 'str'>\n",
      "Feature ParentMaritalStatus -> single is <class 'str'>\n",
      "Feature PracticeSport -> sometimes is <class 'str'>\n",
      "Feature IsFirstChild -> yes is <class 'str'>\n",
      "Feature NrSiblings -> 4.0 is <class 'numpy.float64'>\n",
      "Feature TransportMeans -> school_bus is <class 'str'>\n",
      "Feature WklyStudyHours -> < 5 is <class 'str'>\n",
      "Feature MathScore -> 87 is <class 'numpy.int64'>\n",
      "Feature ReadingScore -> 93 is <class 'numpy.int64'>\n",
      "Feature WritingScore -> 91 is <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(data.columns)):\n",
    "    print(f'Feature {data.columns.values[i]} -> {data.iloc[2].iloc[i]} is {type(data.iloc[2].iloc[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. For numerical features print the value of mean, standard deviation and median. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Unnamed: 0:\n",
      "\tMean -> 499.5566071603407\n",
      "\tStandard deviation -> 288.74318261024985\n",
      "\tMedian -> 500.0\n",
      "Feature StudentId:\n",
      "\tMean -> 549614.8522567801\n",
      "\tStandard deviation -> 257909.04251609294\n",
      "\tMedian -> 550904.0\n",
      "Feature NrSiblings:\n",
      "\tMean -> 2.1473046888437857\n",
      "\tStandard deviation -> 1.4667205238196086\n",
      "\tMedian -> nan\n",
      "Feature MathScore:\n",
      "\tMean -> 66.5584021409223\n",
      "\tStandard deviation -> 15.361364942374667\n",
      "\tMedian -> 67.0\n",
      "Feature ReadingScore:\n",
      "\tMean -> 69.37753337032082\n",
      "\tStandard deviation -> 14.758710834961404\n",
      "\tMedian -> 70.0\n",
      "Feature WritingScore:\n",
      "\tMean -> 68.41862210763357\n",
      "\tStandard deviation -> 15.443272804689242\n",
      "\tMedian -> 69.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>StudentId</th>\n",
       "      <th>NrSiblings</th>\n",
       "      <th>MathScore</th>\n",
       "      <th>ReadingScore</th>\n",
       "      <th>WritingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30641.000000</td>\n",
       "      <td>30641.000000</td>\n",
       "      <td>29069.000000</td>\n",
       "      <td>30641.000000</td>\n",
       "      <td>30641.000000</td>\n",
       "      <td>30641.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>499.556607</td>\n",
       "      <td>549614.852257</td>\n",
       "      <td>2.147305</td>\n",
       "      <td>66.558402</td>\n",
       "      <td>69.377533</td>\n",
       "      <td>68.418622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.747894</td>\n",
       "      <td>257913.251180</td>\n",
       "      <td>1.466746</td>\n",
       "      <td>15.361616</td>\n",
       "      <td>14.758952</td>\n",
       "      <td>15.443525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100024.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>328156.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>550904.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750.000000</td>\n",
       "      <td>771876.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999992.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      StudentId    NrSiblings     MathScore  ReadingScore  \\\n",
       "count  30641.000000   30641.000000  29069.000000  30641.000000  30641.000000   \n",
       "mean     499.556607  549614.852257      2.147305     66.558402     69.377533   \n",
       "std      288.747894  257913.251180      1.466746     15.361616     14.758952   \n",
       "min        0.000000  100024.000000      0.000000      0.000000     10.000000   \n",
       "25%      249.000000  328156.000000      1.000000     56.000000     59.000000   \n",
       "50%      500.000000  550904.000000      2.000000     67.000000     70.000000   \n",
       "75%      750.000000  771876.000000      3.000000     78.000000     80.000000   \n",
       "max      999.000000  999992.000000     26.000000    100.000000    100.000000   \n",
       "\n",
       "       WritingScore  \n",
       "count  30641.000000  \n",
       "mean      68.418622  \n",
       "std       15.443525  \n",
       "min        4.000000  \n",
       "25%       58.000000  \n",
       "50%       69.000000  \n",
       "75%       79.000000  \n",
       "max      100.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, len(data.columns)):\n",
    "    if type(data.iloc[2].iloc[i]) in [np.int64, np.float64]:\n",
    "        print(f'Feature {data.columns.values[i]}:\\n\\tMean -> {np.mean(data[data.columns[i]])}\\n\\tStandard deviation -> {np.std(data[data.columns[i]])}\\n\\tMedian -> {np.median(data[data.columns[i]])}')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe\n",
    "data.describe(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Check if there are any monotonous attributes. If you find a monotonous attribute, remove it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              1000\n",
       "StudentId              30641\n",
       "Gender                     2\n",
       "EthnicGroup                5\n",
       "ParentEduc                 6\n",
       "LunchType                  2\n",
       "TestPrep                   2\n",
       "ParentMaritalStatus        4\n",
       "PracticeSport              3\n",
       "IsFirstChild              12\n",
       "NrSiblings                11\n",
       "TransportMeans             2\n",
       "WklyStudyHours             3\n",
       "MathScore                 95\n",
       "ReadingScore              90\n",
       "WritingScore              93\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Check the data for missing values. Print the number of missing values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                0\n",
       "StudentId                 0\n",
       "Gender                    0\n",
       "EthnicGroup            1840\n",
       "ParentEduc             1845\n",
       "LunchType                 0\n",
       "TestPrep               1830\n",
       "ParentMaritalStatus    1190\n",
       "PracticeSport           631\n",
       "IsFirstChild            903\n",
       "NrSiblings             1572\n",
       "TransportMeans         3134\n",
       "WklyStudyHours          955\n",
       "MathScore                 0\n",
       "ReadingScore              0\n",
       "WritingScore              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Let's deal with the missing values. \n",
    "\n",
    "a) For the features EthnicGroup, ParentMaritalStatus and WklyStudyHours replace NaN values with the most common value.\n",
    "\n",
    "b) For the feature ParentEduc replace NaN value with a string *no formal education*.\n",
    "\n",
    "c) For the feature TestPrep replace NaN value with a string *none*.\n",
    "\n",
    "d) For the features PracticeSport and IsFirstChild remove all the examples with NaN values. \n",
    "\n",
    "e) For the feature NrSiblings replace the NaN value with the median value.\n",
    "\n",
    "f) Finally, for the feature TransportMeans replace the NaN value with a string *walking*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "StudentId              0\n",
       "Gender                 0\n",
       "EthnicGroup            0\n",
       "ParentEduc             0\n",
       "LunchType              0\n",
       "TestPrep               0\n",
       "ParentMaritalStatus    0\n",
       "PracticeSport          0\n",
       "IsFirstChild           0\n",
       "NrSiblings             0\n",
       "TransportMeans         0\n",
       "WklyStudyHours         0\n",
       "MathScore              0\n",
       "ReadingScore           0\n",
       "WritingScore           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tmp = data.copy()\n",
    "\n",
    "### a)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mode.html\n",
    "data_tmp.loc[data_tmp.EthnicGroup.isna(),'EthnicGroup'] = data_tmp.loc[:,'EthnicGroup'].mode().iloc[0]\n",
    "data_tmp.loc[data_tmp.ParentMaritalStatus.isna(),'ParentMaritalStatus'] = data_tmp.loc[:,'ParentMaritalStatus'].mode().iloc[0]\n",
    "data_tmp.loc[data_tmp.WklyStudyHours.isna(),'WklyStudyHours'] = data_tmp.loc[:,'WklyStudyHours'].mode().iloc[0]\n",
    "\n",
    "### b)\n",
    "data_tmp.loc[data_tmp.ParentEduc.isna(),'ParentEduc'] = 'no formal education'\n",
    "\n",
    "### c)\n",
    "data_tmp.loc[data_tmp.TestPrep.isna(),'TestPrep'] = 'none'\n",
    "\n",
    "### d)\n",
    "data_tmp = data_tmp.loc[data_tmp.PracticeSport.notnull(), :]\n",
    "data_tmp = data_tmp.loc[data_tmp.IsFirstChild.notnull(), :]\n",
    "\n",
    "### e)\n",
    "data_tmp.loc[data_tmp.NrSiblings.isna(),'NrSiblings'] = data_tmp.loc[:,'NrSiblings'].median()\n",
    "\n",
    "### f)\n",
    "data_tmp.loc[data_tmp.TransportMeans.isna(),'TransportMeans'] = 'walking'\n",
    "\n",
    "data_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Are there inconsistencies in the IsFirstChild column? Replace the inconsistent entries so they match the rest of the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NrSiblings</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>26.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rare</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0</td>\n",
       "      <td>3085</td>\n",
       "      <td>3193</td>\n",
       "      <td>2353</td>\n",
       "      <td>1103</td>\n",
       "      <td>485</td>\n",
       "      <td>97</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>2856</td>\n",
       "      <td>4730</td>\n",
       "      <td>4756</td>\n",
       "      <td>3499</td>\n",
       "      <td>1690</td>\n",
       "      <td>780</td>\n",
       "      <td>192</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "NrSiblings  0.0   1.0   2.0   3.0   4.0   5.0   6.0   7.0   10.0  12.0  26.0\n",
       "Title                                                                       \n",
       "Rare           0     3     5     1     1     0     0     1     0     0     0\n",
       "no             0  3085  3193  2353  1103   485    97   102     0     0     1\n",
       "yes         2856  4730  4756  3499  1690   780   192   178     1     1     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_tmp.drop(['Title'], axis=1, inplace=True)\n",
    "\n",
    "data_tmp['Title'] = data_tmp.IsFirstChild.str.extract('([A-Za-z]+)', expand=False)\n",
    "pd.crosstab(data_tmp['Title'], data_tmp['NrSiblings'])\n",
    "\n",
    "# create title Rare\n",
    "data_tmp['Title'] = data_tmp['Title'].replace(['es', 'ye', 'ys'], 'Rare')\n",
    "\n",
    "# switch inconsistent titles\n",
    "data_tmp['Title'] = data_tmp['Title'].replace('Yes', 'yes')\n",
    "data_tmp['Title'] = data_tmp['Title'].replace('si', 'yes')\n",
    "data_tmp['Title'] = data_tmp['Title'].replace('yeah', 'yes')\n",
    "\n",
    "data_tmp['Title'] = data_tmp['Title'].replace('nein', 'no')\n",
    "data_tmp['Title'] = data_tmp['Title'].replace('noo', 'no')\n",
    "data_tmp['Title'] = data_tmp['Title'].replace('nope', 'no')\n",
    "\n",
    "pd.crosstab(data_tmp['Title'], data_tmp['NrSiblings'])\n",
    "\n",
    "# There are examples that has 0 siblings and are not first child\n",
    "data_tmp = data_tmp.drop(data_tmp[(data_tmp.Title == 'no') & (data_tmp.NrSiblings == 0)].index)\n",
    "\n",
    "pd.crosstab(data_tmp['Title'], data_tmp['NrSiblings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The final step to preparing the dataset for classification is transforming the non-numeric variables to numeric variables. \n",
    "For features Gender and LunchType use OneHot Encoder, and for EthnicGroup, ParentEduc, TestPrep, ParentMaritalStatus, PracticeSport, IsFirstChild, TransportMeans and WklyStudyHours use Label Encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EthnicGroup'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EthnicGroup'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     18\u001b[0m le\u001b[38;5;241m.\u001b[39mfit(data\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEthnicGroup\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m data_tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEthnicGroup\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mdata_tmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEthnicGroup\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_tmp\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1329\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1039\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m   1045\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4222\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[1;32m-> 4222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   4223\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EthnicGroup'"
     ]
    }
   ],
   "source": [
    "### OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# Gender\n",
    "encoder.fit(data[['Gender']])\n",
    "# we transform the data\n",
    "data_tmp = encoder.transform(data[['Gender']])\n",
    "data_tmp = pd.DataFrame(data_tmp.toarray(), columns=encoder.get_feature_names_out(['Gender']))\n",
    "\n",
    "# LunchType\n",
    "encoder.fit(data[['LunchType']])\n",
    "# we transform the data\n",
    "data_tmp = encoder.transform(data[['LunchType']])\n",
    "data_tmp = pd.DataFrame(data_tmp.toarray(), columns=encoder.get_feature_names_out(['LunchType']))\n",
    "\n",
    "### LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(data.loc[:,'EthnicGroup'])\n",
    "\n",
    "data_tmp.loc[:,'EthnicGroup'] = le.transform(data_tmp.loc[:,'EthnicGroup'])\n",
    "\n",
    "print(data_tmp.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
